{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Dataset Utilities\n",
    "\n",
    "\"torchdatasetutils\" produces torch [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) classes and utility functions for several imaging datasets.  This currently includes sets of images and annotations from [CVAT](https://github.com/openvinotoolkit/cvat), [COCO dataset](https://cocodataset.org/).  \"torchdatasetutil\" uses an s3 object storage to hold dataset data.  This enables training and test to be performed on nodes different from where the dataset is stored with application defined credentials.  It uses torch PyTorch worker threads to prefetch data for efficient GPU or CPU training and inference.\n",
    "\n",
    "\"torchdatasetutils\" takes as an input the [pymlutil](https://pypi.org/project/pymlutil/).s3 object to access the object storage.\n",
    "\n",
    "Two json or yaml dictionaries are loaded from the object storage to identify and process the dataset: the dataset description and class dictionary.  The the dataset description is unique for each type of dataset.  The class dictionary is common to all datasets and describes data transformation and data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library structure\n",
    "- pymlutil.s3: access to object torage\n",
    "- [torchdatasetutil](https://pypi.org/project/torchdatasetutil/)\n",
    "    - [gitcoco.getcoco](https://github.com/bhlarson/torchdatasetutil/blob/main/torchdatasetutil/getcoco.py#L25): function to load the [COCO dataset](https://cocodataset.org/) from internet archives into object storage\n",
    "    - [cocostore](https://github.com/bhlarson/torchdatasetutil/blob/main/torchdatasetutil/cocostore.py)\n",
    "        - [CocoStore](https://github.com/bhlarson/torchdatasetutil/blob/main/torchdatasetutil/cocostore.py#L17): class providing a python iterator over the coco dataset in object storage\n",
    "        - [CocoDataset](https://github.com/bhlarson/torchdatasetutil/blob/main/torchdatasetutil/cocostore.py)\" class implementing the pytorch [Dataset class](https://pytorch.org/docs/stable/data.html#dataset-types) for the CocoStore iterator\n",
    "        - CreateCocoLoaders: function returning set of torch dataloders of CocoDatasets.\n",
    "    - [imstore](https://github.com/bhlarson/torchdatasetutil/blob/main/torchdatasetutil/imstore.py)\n",
    "        - ImagesStore: class providing python iterator over sets of images for dataset inference.\n",
    "        - ImagesDataset: Torch dataset derived class augmenting and extaracting random crops for training and test.\n",
    "        - CreateImageLoaders: function returning set of torch dataloaders of ImagesDatasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymlutil.s3 import s3store, Connect\n",
    "from torchdatasetutil.imstore import ImagesStore, CreateImageLoaders\n",
    "from torchdatasetutil.cocostore import CocoStore, CreateCocoLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'store',\n",
       " 'type': 'trainer',\n",
       " 'address': '198.211.145.1:30990',\n",
       " 'tls': False,\n",
       " 'sets': {'dataset': {'bucket': 'mllib',\n",
       "   'prefix': 'data',\n",
       "   'dataset_filter': ''},\n",
       "  'trainingset': {'bucket': 'mllib',\n",
       "   'prefix': 'training',\n",
       "   'dataset_filter': ''},\n",
       "  'model': {'bucket': 'mllib', 'prefix': 'model', 'dataset_filter': ''},\n",
       "  'test': {'bucket': 'mllib', 'prefix': 'test', 'dataset_filter': ''}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credentials = \"creds.yaml\"\n",
    "s3, creds, s3def = Connect(credentials)\n",
    "s3def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create images dataset\n",
    "images_path = 'testimages'\n",
    "dataset_name = 'testimages'\n",
    "s3.PuthDir(s3def['sets']['dataset']['bucket'], images_path, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imstore dataset\n",
    "torchdatasetutil.imstore ImagesStore produces an [iterator object](https://docs.python.org/3/c-api/iterator.html) from a set of images in an object store.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucket': 'mllib',\n",
       " 'prefix': 'annotations/lit',\n",
       " 'image_path': None,\n",
       " 'image_pattern': '*.tif',\n",
       " 'image_colorspace': 'grayscale',\n",
       " 'label_path': None,\n",
       " 'label_in_image_path': True,\n",
       " 'label_pattern': '*_cls.png',\n",
       " 'recursive': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_desc = 'annotations/lit/dataset.yaml'\n",
    "dataset_desc_example = s3.GetDict(s3def['sets']['dataset']['bucket'],dataset_desc)\n",
    "dataset_desc_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'background': 0,\n",
       " 'ignore': 255,\n",
       " 'classes': 2,\n",
       " 'objects': [{'id': 0,\n",
       "   'name': 'unlabeled',\n",
       "   'trainId': 0,\n",
       "   'category': 'void',\n",
       "   'display': False,\n",
       "   'color': [0, 0, 0]},\n",
       "  {'id': 1,\n",
       "   'name': 'FibLine',\n",
       "   'trainId': 1,\n",
       "   'category': 'vehicle',\n",
       "   'display': True,\n",
       "   'color': [255, 0, 0]},\n",
       "  {'id': 9,\n",
       "   'name': 'FibLine',\n",
       "   'trainId': 1,\n",
       "   'category': 'vehicle',\n",
       "   'display': True,\n",
       "   'color': [255, 0, 0]}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dictionary = 'model/crisplit/lit.json'\n",
    "class_dictionary_example = s3.GetDict(s3def['sets']['dataset']['bucket'],class_dictionary)\n",
    "class_dictionary_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2819687617.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_3792687/2819687617.py\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "bucket = s3def['sets']['dataset']['bucket']\n",
    "\n",
    "\n",
    "dataset_desc = s3.GetDict(s3def['sets']['dataset']['bucket'],dataset_desc)\n",
    "\n",
    "\n",
    "self.store = ImagesStore(s3, bucket, dataset_desc, class_dictionary)\n",
    "\n",
    "\n",
    "class_dictionary = s3.GetDict(s3def['sets']['dataset']['bucket'],args.class_dict) \n",
    "os.makedirs(args.test_path, exist_ok=True)\n",
    "\n",
    "store = CocoStore(s3, bucket=s3def['sets']['dataset']['bucket'], \n",
    "                    dataset_desc=args.dataset_train, \n",
    "                    image_paths=args.train_image_path, \n",
    "                    class_dictionary=args.class_dict, \n",
    "                    imflags=args.imflags)\n",
    "\n",
    "for i, iman in enumerate(store):\n",
    "    img = store.MergeIman(iman['img'], iman['ann'])\n",
    "    write_path = '{}cocostoreiterator{:03d}.png'.format(args.test_path, i)\n",
    "    cv2.imwrite(write_path,img)\n",
    "    if i >= args.num_images:\n",
    "        print ('test_iterator complete')\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
